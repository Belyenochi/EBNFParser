

Cast Map
=================


.. code ::

    SomeToken as S := 'abc';
    Alpha          := R'[a-z]+';
    F ::= S'abc' | Alpha;


The ruiko codes above defines a tokenize named :code:`SomeToken` with a prefix :code:`S`.


When the input source is splitted into a series of :code:`Tokenizers` , however, even the literal parser
:code:`Alpha` is supposed to match all string matched by regex pattern :code:`"[a-z]+"`, it cannot match a tokenizer
with string :code:`"abc"` generated by EBNFParser automatical tokenizing, 
that's because all the :code:`"all"` has been casted into a unique string in a buffer pool, 
and **all of them have the same name** :code:`SomeToken`, **not** :code:`Alpha`.

Here is a string with value :code:`"abc"` with an unique memory address, 
and every literal parser defined by :code:`"abc"` just matched it only.

The literal parser defined as :code:`Alpha := R'[a-z]+'` just matches the tokenizer whose name is :code:`Alpha`.


Prefix
======================

If you're using custom tokenizing, several :code:`Tokenizer` object 
with the same string "abc"(and have the same memory address)
could have different names.

To distinguish from each other, you can do as the following:

- Grammar

.. code ::

    SomeToken as S := 'abc';
    Alpha          := R'[a-z]+';
    F ::= S'abc' | Alpha;
    G ::= 'abc';
    H ::= G | F ;

.. code ::

    Tokenizers:
        [name: SomeToken, string: "abc"]
        ...

If you are using combined parser :code:`G` to match these tokenizers, you'll fail,
because in the grammar :code:`G` is defined as :code:`G::='abc'` , it means :code:`G` only accepts
the a tokenizer who has an attribute :code:`name="auto_const"` and another attribute :code:`string="abc"`
(and it's from the unique buff pool, not a string created by regex matching).
